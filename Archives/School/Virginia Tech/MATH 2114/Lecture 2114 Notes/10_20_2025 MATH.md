

# DUMP


**Def**
A Non-zero vector $\vec{x}$ is an eigenvector of $A$, if there exists scalar $\lambda \in \mathbb{R}$ when, $A \vec{x}=\lambda\vec{x}$ considering $\lambda$ the eigenvalue of $A$ associated with $\vec{x}$

- zero vector is not an eigenvector
- is a constant which does the same thing as a linear transformation to a given vector (the eigenvector)x
- A can only be square for eigenvalues/vectors to exist.

$$
(A- \lambda I_{n})  \vec{x}= \vec{0}
$$
> compute the homogenous system for a given eigenvalue to find the set of eigenvectors for that value


$$
\begin{array}{ll}  
A\vec{x} = \lambda   \vec{x} \\
(A- \lambda I_{n})  \vec{x}= \vec{0}
\end{array}
$$

### 4.2

**Def** Determinants 

$$
A =

\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
$$
$Det(A)=ad-bc$


Notation given A $n\times n$. Let $A_{ij}$ be the matrix where we eliminate row $i$ and column $j$
$$
A= \begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{bmatrix}, \,
B_{\text{reduced}} =\begin{bmatrix}
5 & 6 \\
8 & 9
\end{bmatrix}
$$
- This is where we reduced A by removing column 1 and row 1 



**Calculating the Determinant**

To calculate $Det(A)$ you can "expand" upon row $i$ 
$$
Det(A) = \sum_{j=1}^n a_{ij}(-1)^{i+j} \cdot \det(A_{ij})
$$

- We can only do the determinant on square matrices 
- When given a matrix larger than $3\times 3$ one must reduce each "internal" determinant recursively untill given a $2 \times 2$ matrix where the formula $\det (A_{2 \times 2})=ad-bc$ 


- The determinant of an triangular matrix is just the product of the diagonals 
	- A matrix is triangular if all of the entries bellow the diagonal are zero. 


- Row multiplication multiplies the determinant
- Scalar multiplicative addition doesn't affect the determinant
	- Interchanging rows multiplies the row by zero 


- You cant take the determinant of rows as well as columns so if your matrix has a column that makes it easier to take the determinant then take the determinant of that column like you would of a row.




### Other properties of determinants 

$A,b - n\times n$

- $Det(kA)=k^n\det(A)$
- $\det (A) = \det (A^T)$ 
- $\det (AB) =\det (A) \cdot \det(B)$

- We mainly use determinants to calculate eigenvalues 

- $\det(A-\lambda I_{n})$ 
	- is a $n$-degree polynomial whose roots are the e-values of $A$

- $g_{i}$ is the dimension of the eigenspace 
- the dimension of $g_{i}$ is called the geometric multiplicity. 


**Eigen Value theorems**

- The eigenvalue of a triangular matrix is a product of the diagonal entries 
- Given an $n\times n$ matrix A, A has at **most** $n-$distinct eigenvalues
- $\lambda$ is only an eigen value if $(A-\lambda I_{n})$ is **not** an invertible matrix  


**Theorem 3.4**
If $\lambda$ is a an eigen value of the matrix:

$A.$ If
$$
\begin{array}{rr}
d=\text{algabraic multiplicity} \\
g= \text{geometric multiplicity} 
\end{array}
$$
then $g\leq d$


if $\lambda^i$ has algebraic multiplicity $d_{i}$ 
$$
\sum d_{i}=n \, (\text{size of matrix})
$$



**Theorem**
suppose $S_{1}$ is a basis for the eigenspace $E_{\lambda_{1}}$. 

If $S_{2}$ is a basis for $E_{\lambda_{2}}$

Then $S_{1} \cup S_{2}$ us a linearly independent set 


## questions

- Considering there could be many different eigenvectors and eigenvalues for a given matrix are eigenvectors and eigenvalues a subspace of the standard matrix of the given linear transformation? 



$$
\begin{bmatrix}
\colorbox{darkred} {$a_{1,1}$}  & a_{1,2}  & \dots  &  a_{1,j} \\
a_{21} & \colorbox{darkred} {$a_{2,1}$}  & \dots &  a_{2j} \\
\vdots  & \vdots &  & \vdots \\
a_{i,1}  & a_{i,2}  & \dots & \colorbox{darkred} {$a_{i,j}$}
\end{bmatrix}
$$